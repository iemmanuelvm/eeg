{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae06d4a0-ef2c-4a5f-bc0d-253674ddd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install mne\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f05679-088c-4642-8859-59bf966dc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1306f27-0a35-47a6-bd50-fba0ee43c5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 22, 15000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.randn(3,22,15000)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1789c4b8-f2ff-4464-830e-2c79ee114633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self,inplace):\n",
    "    super().__init__()\n",
    "    self.conv1=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=2,stride=2,padding=0)\n",
    "    self.conv2=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=4,stride=2,padding=1)\n",
    "    self.conv3=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=8,stride=2,padding=3)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x1=self.relu(self.conv1(x))\n",
    "    x2=self.relu(self.conv2(x))\n",
    "    x3=self.relu(self.conv3(x))\n",
    "    x=torch.cat([x1,x3,x3],dim=1)\n",
    "    return x\n",
    "     \n",
    "\n",
    "class ChronoNet(nn.Module):\n",
    "  def __init__(self,channel):\n",
    "    super().__init__()\n",
    "    self.block1=Block(channel)\n",
    "    self.block2=Block(96)\n",
    "    self.block3=Block(96)\n",
    "    self.gru1=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru2=nn.GRU(input_size=32,hidden_size=32,batch_first=True)\n",
    "    self.gru3=nn.GRU(input_size=64,hidden_size=32,batch_first=True)\n",
    "    self.gru4=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru_linear=nn.Linear(64,1)\n",
    "    self.flatten=nn.Flatten()\n",
    "    self.fc1=nn.Linear(32,1)\n",
    "    self.relu=nn.ReLU()\n",
    "  def forward(self,x):\n",
    "    x=self.block1(x)\n",
    "    x=self.block2(x)\n",
    "    x=self.block3(x)\n",
    "    x=x.permute(0,2,1)\n",
    "    gru_out1,_=self.gru1(x)\n",
    "    gru_out2,_=self.gru2(gru_out1)\n",
    "    gru_out=torch.cat([gru_out1,gru_out2],dim=2)\n",
    "    gru_out3,_=self.gru3(gru_out)\n",
    "    gru_out=torch.cat([gru_out1,gru_out2,gru_out3],dim=2)\n",
    "    #print('gru_out',gru_out.shape)\n",
    "    linear_out=self.relu(self.gru_linear(gru_out.permute(0,2,1)))\n",
    "    gru_out4,_=self.gru4(linear_out.permute(0,2,1))\n",
    "    x=self.flatten(gru_out4)\n",
    "    x=self.fc1(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baf40787-02ea-4a95-a235-d85f15ae8d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.randn(3,14,512)\n",
    "input.shape\n",
    "model=ChronoNet(14)\n",
    "out=model(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f03e745e-71c8-4f7e-a017-269d1009d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDD_data_path='./data/Data/CleanData/CleanData_TDC/Rest'\n",
    "TDC_data_path='./data/Data/CleanData/CleanData_IDD/Rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "925a51a4-b6c9-40f9-b5f1-ff098c501dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmat2mne(data):\n",
    "  ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "  ch_types = ['eeg'] * 14\n",
    "  sampling_freq=128\n",
    "  info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "  info.set_montage('standard_1020')\n",
    "  data=mne.io.RawArray(data, info)\n",
    "  data.set_eeg_reference()\n",
    "  data.filter(l_freq=1,h_freq=30)\n",
    "  epochs=mne.make_fixed_length_epochs(data,duration=4,overlap=0)\n",
    "  return epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2f86d9b-ea23-4674-b5e8-ebcc625976ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "idd_subject=[]\n",
    "for idd in glob(IDD_data_path+'/*.mat'):\n",
    "  data=scipy.io.loadmat(idd)['clean_data']\n",
    "  data=convertmat2mne(data)\n",
    "  idd_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d20c5f6-ab12-4348-9a7f-f6103e4dd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "tdc_subject=[]\n",
    "for tdc in glob(TDC_data_path+'/*.mat'):\n",
    "  data=scipy.io.loadmat(tdc)['clean_data']\n",
    "  data=convertmat2mne(data)\n",
    "  tdc_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "105cdf56-12aa-4dd6-9658-6fa95979fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idd_subject),len(tdc_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "324d36ab-0de4-454c-accc-cc297da18681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n"
     ]
    }
   ],
   "source": [
    "control_epochs_labels=[len(i)*[0] for i in tdc_subject]\n",
    "patients_epochs_labels=[len(i)*[1] for i in idd_subject]\n",
    "print(len(control_epochs_labels),len(patients_epochs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "327475dc-2cea-4a1b-9909-e7ed3217b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 14\n"
     ]
    }
   ],
   "source": [
    "data_list=tdc_subject+idd_subject\n",
    "label_list=control_epochs_labels+patients_epochs_labels\n",
    "groups_list=[[i]*len(j) for i, j in enumerate(data_list)]\n",
    "print(len(data_list),len(label_list),len(groups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c296060-5f16-4732-9012-b2f9080fd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf=GroupKFold()\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "class StandardScaler3D(BaseEstimator,TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape( -1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5500d9f6-bc2b-4e7e-85a3-5c22ae06ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 512, 14) (420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_array=np.concatenate(data_list)\n",
    "label_array=np.concatenate(label_list)\n",
    "group_array=np.concatenate(groups_list)\n",
    "data_array=np.moveaxis(data_array,1,2)\n",
    "\n",
    "print(data_array.shape,label_array.shape,group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73340d5b-088d-4e95-8570-a7fef06b8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler3D()\n",
    "    train_features=scaler.fit_transform(train_features)\n",
    "    val_features=scaler.transform(val_features)\n",
    "    train_features=np.moveaxis(train_features,1,2)\n",
    "    val_features=np.moveaxis(val_features,1,2)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de293f9d-92ba-4f21-a133-27e5dd4f03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.Tensor(train_features)\n",
    "val_features = torch.Tensor(val_features)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "val_labels = torch.Tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89b0c850-3243-47cf-ab9c-e603e6fcec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 90)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_features),len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca410d9f-b973-4221-bc13-6aa345517f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([330, 14, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b12d254b-accb-47e4-a683-3c5992f51a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule,Trainer\n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e9dd99d-4651-45b0-b718-c6e49ea85917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class ChronoModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(ChronoModel, self).__init__()\n",
    "        self.model = ChronoNet(14)\n",
    "        self.lr = 1e-3\n",
    "        self.bs = 12\n",
    "        self.worker = 2\n",
    "        self.acc = torchmetrics.Accuracy(task='binary')\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.training_accuracies = []  # To store accuracies for training\n",
    "        self.validation_accuracies = []  # To store accuracies for validation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(train_features, train_labels)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.bs, num_workers=self.worker, shuffle=True)\n",
    "        return dataloader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.criterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        self.training_accuracies.append(acc)  # Store training accuracy\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate and log the average accuracy and loss for the epoch\n",
    "        avg_acc = torch.stack(self.training_accuracies).mean().detach().cpu().numpy().round(2)\n",
    "        print(f'Train Accuracy: {avg_acc}')\n",
    "        self.training_accuracies = []  # Reset for next epoch\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(val_features, val_labels)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.bs, num_workers=self.worker, shuffle=False)\n",
    "        return dataloader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.criterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        self.validation_accuracies.append(acc)  # Store validation accuracy\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate and log the average accuracy and loss for the epoch\n",
    "        avg_acc = torch.stack(self.validation_accuracies).mean().detach().cpu().numpy().round(2)\n",
    "        print(f'Validation Accuracy: {avg_acc}')\n",
    "        self.validation_accuracies = []  # Reset for next epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0dacd921-9ad4-427a-8ec8-b713cb1968a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChronoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4eaf93b5-677f-4ca8-92b5-9a58e1535642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer=Trainer(max_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b6e0583-3454-4baf-af1a-f9c0ac94ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | ChronoNet         | 133 K  | train\n",
      "1 | acc       | BinaryAccuracy    | 0      | train\n",
      "2 | criterion | BCEWithLogitsLoss | 0      | train\n",
      "--------------------------------------------------------\n",
      "133 K     Trainable params\n",
      "0         Non-trainable params\n",
      "133 K     Total params\n",
      "0.534     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000ef30587bb4623bc6f853dce65acbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iemma\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iemma\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "C:\\Users\\iemma\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e2e0a7df064891be404f33bcaca52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90be98aadcc475b879db8847f4a7010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3100000023841858\n",
      "Train Accuracy: 0.5400000214576721\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a32327-c32b-4b12-93c7-e3ff73dfc212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
