import numpy as np
import matplotlib.pyplot as plt
import torch
import torchaudio
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import random
import time
%matplotlib qt


class Plotter():
    def __init__(self, win_size=96, n_wins=10, n_bands=129, n_classes=2, msd_labels=None, FIG_SIZE=(10,6), blit=True):
        # Inicializa parámetros
        self.blit = blit
        self.win_size = win_size
        self.n_wins = n_wins
        self.n_bands = n_bands
        self.n_classes = n_classes
        self.msd_labels = msd_labels

        # Inicializa datos para las gráficas
        self.spec = np.zeros((n_bands, win_size * n_wins))
        self.act = np.zeros((n_classes, n_wins))

        # Configura figuras
        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1, figsize=FIG_SIZE)

        # Espectrograma
        self.img1 = self.ax1.imshow(self.spec, vmin=0, vmax=1, interpolation="None", cmap="jet", aspect='auto')
        self.ax1.set_title("Espectrograma")
        self.ax1.invert_yaxis()

        # Activaciones de Clase
        self.img2 = self.ax2.imshow(self.act, vmin=0, vmax=1, interpolation="None", aspect='auto')
        self.ax2.set_title("Activaciones de Clase")

        if msd_labels is not None:
            self.ax2.set_yticks(np.linspace(0, len(msd_labels), len(msd_labels), endpoint=False))
            self.ax2.set_yticklabels(msd_labels)
            self.ax2.set_ylim(-0.5, len(msd_labels)-0.5)

        self.fig.canvas.draw()

        if self.blit:
            # Cachear el fondo de las gráficas
            self.axbackground1 = self.fig.canvas.copy_from_bbox(self.ax1.bbox)
            self.axbackground2 = self.fig.canvas.copy_from_bbox(self.ax2.bbox)

        plt.ion()
        plt.show()

    def update(self, new_spec_col, new_act_col):
        # Actualizar los datos de la espectrograma
        self.spec = np.delete(self.spec, [k for k in range(self.win_size)], axis=1)
        self.spec = np.concatenate((self.spec, new_spec_col), axis=1)
        self.img1.set_data(self.spec)
        self.img1.autoscale()

        # Actualizar los datos de las activaciones
        self.act = np.delete(self.act, 0, axis=1)
        self.act = np.concatenate((self.act, new_act_col), axis=1)
        self.img2.set_data(self.act)
        self.img2.autoscale()

        if self.blit:
            # Restaurar el fondo de las gráficas
            self.fig.canvas.restore_region(self.axbackground1)
            self.fig.canvas.restore_region(self.axbackground2)

            # Redibujar los artistas
            self.ax1.draw_artist(self.img1)
            self.ax2.draw_artist(self.img2)

            # Actualizar las regiones
            self.fig.canvas.blit(self.ax1.bbox)
            self.fig.canvas.blit(self.ax2.bbox)
        else:
            self.fig.canvas.draw()

        self.fig.canvas.flush_events()



fs = 8000
duration = 1.0
t = np.linspace(0, duration, int(fs * duration), endpoint=False)


def generate_signal(func, freq=5, phase=0):
    global t
    if func == 'sine':
        return np.sin(2 * np.pi * freq * t + phase)
    elif func == 'tangent':
        return np.tan(2 * np.pi * freq * t + phase) * 0.1
    else:
        raise ValueError("Función desconocida. Usa 'sine' o 'tangent'.")


n_fft = 256
hop_length = 128
window = torch.hamming_window(n_fft)


def compute_stft(signal):
    signal_tensor = torch.tensor(signal, dtype=torch.float32)
    stft = torch.stft(signal_tensor, n_fft=n_fft, hop_length=hop_length, window=window, return_complex=True)
    magnitude = torch.abs(stft)
    magnitude = magnitude / (magnitude.max() + 1e-8)
    return magnitude


class TrigDataset(Dataset):
    def __init__(self, num_samples=1000, transform=None):
        self.num_samples = num_samples
        self.transform = transform
        self.classes = ['sine', 'tangent']

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        label = random.randint(0, 1)
        func = self.classes[label]

        freq = random.uniform(1, 50)
        phase = random.uniform(0, 2 * np.pi)
        
        signal = generate_signal(func, freq, phase)

        stft = compute_stft(signal)

        if self.transform:
            stft = self.transform(stft)

        stft = stft.unsqueeze(0)
        return stft, label


class STFTClassifier(nn.Module):
    def __init__(self, n_classes=2):
        super(STFTClassifier, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 32 * 15, 128)
        self.fc2 = nn.Linear(128, n_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


def train_model():
    train_dataset = TrigDataset(num_samples=3000)
    test_dataset = TrigDataset(num_samples=600)

    batch_size = 16
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    model = STFTClassifier(n_classes=2)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    num_epochs = 10
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(num_epochs):
        running_loss = 0.0
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_dataset)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = correct / total * 100
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Test Accuracy: {accuracy:.2f}%")

    model.eval()
    correct = 0
    total = 0
    confusion_matrix = np.zeros((2, 2), dtype=int)

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            for t_label, p_label in zip(labels.view(-1), predicted.view(-1)):
                confusion_matrix[t_label.long(), p_label.long()] += 1

    accuracy = correct / total * 100
    print(f"Precisión en el conjunto de prueba: {accuracy:.2f}%")
    print("Matriz de Confusión:")
    print(confusion_matrix)

    # Guardar el modelo entrenado
    torch.save(model.state_dict(), "stft_classifier.pth")
    print("Modelo guardado como 'stft_classifier.pth'.")








# ---------------------------- ENTRENAMIENTO DEL MODELO ----------------------------



# ---------------------------- VISUALIZACIÓN EN TIEMPO REAL ----------------------------



# ---------------------------- MAIN ----------------------------

if __name__ == "__main__":
    import os

    # Verificar si el modelo ya está entrenado
    modelo_guardado = "stft_classifier.pth"
    if not os.path.exists(modelo_guardado):
        print("Entrenando el modelo...")
        train_model()
    else:
        print("Modelo ya entrenado. Iniciando la visualización en tiempo real.")

    # Iniciar la visualización en tiempo real
    real_time_plotting(model_path=modelo_guardado)



import numpy as np
import matplotlib.pyplot as plt
import torch
import torchaudio
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import random
import time
import os

# Configuración de Matplotlib para usar una ventana externa (Qt)
%matplotlib qt

# ---------------------------- CLASE PLOTTER ----------------------------

class Plotter():
    def __init__(self, win_size=96, n_wins=10, n_bands=129, n_classes=2, msd_labels=None, FIG_SIZE=(12, 8), blit=True):
        """
        Inicializa la clase Plotter con tres subgráficas: Señal en Tiempo, Espectrograma y Activaciones de Clase.

        Args:
            win_size (int): Tamaño de la ventana para la actualización del espectrograma.
            n_wins (int): Número de ventanas para mostrar en el espectrograma y activaciones.
            n_bands (int): Número de bandas de frecuencia en el espectrograma.
            n_classes (int): Número de clases para las activaciones.
            msd_labels (list, optional): Etiquetas de las clases.
            FIG_SIZE (tuple, optional): Tamaño de la figura.
            blit (bool, optional): Si se usa blitting para actualizaciones más eficientes.
        """
        # Inicializar parámetros
        self.blit = blit
        self.win_size = win_size
        self.n_wins = n_wins
        self.n_bands = n_bands
        self.n_classes = n_classes
        self.msd_labels = msd_labels

        # Inicializar datos para las gráficas
        # Señal en Tiempo
        self.signal_length = 1024  # Longitud de la señal a mostrar
        self.signal = np.zeros(self.signal_length)

        # Espectrograma
        self.spec = np.zeros((n_bands, win_size * n_wins))

        # Activaciones de Clase
        self.act = np.zeros((n_classes, n_wins))

        # Configurar figuras
        self.fig, (self.ax_signal, self.ax_spec, self.ax_act) = plt.subplots(3, 1, figsize=FIG_SIZE)

        # Señal en Tiempo
        self.line_signal, = self.ax_signal.plot(self.signal, color='blue')
        self.ax_signal.set_title("Señal en Tiempo")
        self.ax_signal.set_xlabel("Muestras")
        self.ax_signal.set_ylabel("Amplitud")
        self.ax_signal.set_ylim(-1.5, 1.5)

        # Espectrograma
        self.img_spec = self.ax_spec.imshow(self.spec, vmin=0, vmax=1, interpolation="None", cmap="jet", aspect='auto')
        self.ax_spec.set_title("Espectrograma")
        self.ax_spec.invert_yaxis()

        # Activaciones de Clase
        self.img_act = self.ax_act.imshow(self.act, vmin=0, vmax=1, interpolation="None", aspect='auto')
        self.ax_act.set_title("Activaciones de Clase")

        if msd_labels is not None:
            self.ax_act.set_yticks(np.linspace(0, len(msd_labels), len(msd_labels), endpoint=False))
            self.ax_act.set_yticklabels(msd_labels)
            self.ax_act.set_ylim(-0.5, len(msd_labels)-0.5)

        self.fig.tight_layout()
        self.fig.canvas.draw()

        if self.blit:
            # Cachear el fondo de las gráficas
            self.axbackground_signal = self.fig.canvas.copy_from_bbox(self.ax_signal.bbox)
            self.axbackground_spec = self.fig.canvas.copy_from_bbox(self.ax_spec.bbox)
            self.axbackground_act = self.fig.canvas.copy_from_bbox(self.ax_act.bbox)

        plt.ion()  # Modo interactivo
        plt.show()

    def update(self, new_signal, new_spec_col, new_act_col):
        """
        Actualiza las gráficas con nuevos datos.

        Args:
            new_signal (np.ndarray): Nueva señal en tiempo para actualizar.
            new_spec_col (np.ndarray): Nueva columna de espectrograma.
            new_act_col (np.ndarray): Nuevas activaciones de clase.
        """
        # Actualizar la señal en tiempo
        self.signal = np.delete(self.signal, [k for k in range(len(new_signal))], axis=0)
        self.signal = np.concatenate((self.signal, new_signal), axis=0)
        self.line_signal.set_ydata(self.signal)

        # Actualizar los datos del espectrograma
        self.spec = np.delete(self.spec, [k for k in range(self.win_size)], axis=1)
        self.spec = np.concatenate((self.spec, new_spec_col), axis=1)
        self.img_spec.set_data(self.spec)
        self.img_spec.autoscale()

        # Actualizar las activaciones de clase
        self.act = np.delete(self.act, 0, axis=1)
        self.act = np.concatenate((self.act, new_act_col), axis=1)
        self.img_act.set_data(self.act)
        self.img_act.autoscale()

        if self.blit:
            # Restaurar el fondo de las gráficas
            self.fig.canvas.restore_region(self.axbackground_signal)
            self.fig.canvas.restore_region(self.axbackground_spec)
            self.fig.canvas.restore_region(self.axbackground_act)

            # Redibujar los artistas
            self.ax_signal.draw_artist(self.line_signal)
            self.ax_spec.draw_artist(self.img_spec)
            self.ax_act.draw_artist(self.img_act)

            # Actualizar las regiones
            self.fig.canvas.blit(self.ax_signal.bbox)
            self.fig.canvas.blit(self.ax_spec.bbox)
            self.fig.canvas.blit(self.ax_act.bbox)
        else:
            self.fig.canvas.draw()

        self.fig.canvas.flush_events()

# ---------------------------- GENERACIÓN DE SEÑALES ----------------------------

# Parámetros de la señal
fs = 8000  # Frecuencia de muestreo en Hz
duration = 1.0  # Duración en segundos
t = np.linspace(0, duration, int(fs * duration), endpoint=False)

def generate_signal(func, freq=5, phase=0):
    """
    Genera una señal basada en la función especificada.

    Args:
        func (str): 'sine' o 'cosine'.
        freq (float): Frecuencia de la señal en Hz.
        phase (float): Fase de la señal en radianes.

    Returns:
        np.ndarray: Señal generada.
    """
    global t  # Usar la variable global 't'

    if func == 'sine':
        return np.sin(2 * np.pi * freq * t + phase)
    elif func == 'cosine':
        return np.tan(2 * np.pi * freq * t + phase) * 0.1  # Implementación correcta de 'cosine'
    else:
        raise ValueError("Función desconocida. Usa 'sine' o 'cosine'.")

# ---------------------------- CÁLCULO DE STFT ----------------------------

# Parámetros de STFT
n_fft = 256
hop_length = 128
window = torch.hamming_window(n_fft)

def compute_stft(signal):
    """
    Calcula la STFT de una señal.

    Args:
        signal (np.ndarray): Señal de entrada.

    Returns:
        torch.Tensor: Magnitud de la STFT.
    """
    signal_tensor = torch.tensor(signal, dtype=torch.float32)
    stft = torch.stft(signal_tensor, n_fft=n_fft, hop_length=hop_length, window=window, return_complex=True)
    magnitude = torch.abs(stft)
    # Normalización
    magnitude = magnitude / (magnitude.max() + 1e-8)  # Añadir epsilon para evitar división por cero
    return magnitude

# ---------------------------- DATASET Y DATA LOADER ----------------------------

class TrigDataset(Dataset):
    def __init__(self, num_samples=1000, transform=None):
        """
        Inicializa el dataset.

        Args:
            num_samples (int): Número total de muestras.
            transform (callable, optional): Transformación a aplicar.
        """
        self.num_samples = num_samples
        self.transform = transform
        self.classes = ['sine', 'cosine']  # Dos clases

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # Selección aleatoria de la clase
        label = random.randint(0, 1)
        func = self.classes[label]

        # Parámetros aleatorios
        freq = random.uniform(1, 50)  # Frecuencia entre 1 y 50 Hz
        phase = random.uniform(0, 2 * np.pi)  # Fase entre 0 y 2π

        # Generación de la señal
        signal = generate_signal(func, freq, phase)

        # Cálculo de STFT
        stft = compute_stft(signal)

        # Opcional: aplicar transformaciones adicionales
        if self.transform:
            stft = self.transform(stft)

        # Añadir un canal adicional para compatibilidad con CNN
        stft = stft.unsqueeze(0)  # [1, freq_bins, time_frames]

        return stft, label

# ---------------------------- MODELO DE CLASIFICACIÓN ----------------------------

class STFTClassifier(nn.Module):
    def __init__(self, n_classes=2):
        super(STFTClassifier, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # [batch, 1, freq_bins, time_frames]
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # [batch, 16, freq_bins/2, time_frames/2]

        # Calculamos el tamaño después de las capas convolucionales y de pooling
        # Para n_fft=256, freq_bins=129
        # Después de la primera pooling: 129 / 2 = 64 (MaxPool2d truncará a 64)
        # Después de la segunda pooling: 64 / 2 = 32
        # Suponiendo time_frames=62 después de STFT
        # Después de pooling: 62 / 2 = 31, luego 31 / 2 = 15 (truncado)
        # Así que la salida de conv2 es [batch, 32, 32, 15]

        self.fc1 = nn.Linear(32 * 32 * 15, 128)  # Ajusta según las dimensiones reales
        self.fc2 = nn.Linear(128, n_classes)  # 2 clases: sine, cosine

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # [batch, 16, 64, 31]
        x = self.pool(F.relu(self.conv2(x)))  # [batch, 32, 32, 15]
        x = x.view(x.size(0), -1)  # Aplanar
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ---------------------------- ENTRENAMIENTO DEL MODELO ----------------------------

def train_model():
    """
    Entrena el modelo STFTClassifier con el dataset TrigDataset.
    """
    # Crear datasets de entrenamiento y prueba
    train_dataset = TrigDataset(num_samples=3000)
    test_dataset = TrigDataset(num_samples=600)

    # Crear DataLoaders
    batch_size = 16
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Instanciar el modelo, la función de pérdida y el optimizador
    model = STFTClassifier(n_classes=2)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Entrenamiento
    num_epochs = 10
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(num_epochs):
        running_loss = 0.0
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zerar gradientes
            optimizer.zero_grad()

            # Forward
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_dataset)

        # Evaluación en el conjunto de prueba
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = correct / total * 100
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Test Accuracy: {accuracy:.2f}%")

    # Evaluación final
    model.eval()
    correct = 0
    total = 0
    confusion_matrix = np.zeros((2, 2), dtype=int)

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # Construcción de la matriz de confusión
            for t_label, p_label in zip(labels.view(-1), predicted.view(-1)):
                confusion_matrix[t_label.long(), p_label.long()] += 1

    accuracy = correct / total * 100
    print(f"Precisión en el conjunto de prueba: {accuracy:.2f}%")
    print("Matriz de Confusión:")
    print(confusion_matrix)

    # Guardar el modelo entrenado
    torch.save(model.state_dict(), "stft_classifier.pth")
    print("Modelo guardado como 'stft_classifier.pth'.")

# ---------------------------- VISUALIZACIÓN EN TIEMPO REAL ----------------------------

def real_time_plotting(model_path="stft_classifier.pth"):
    """
    Inicia la visualización en tiempo real de la señal, el espectrograma y las activaciones de clase.

    Args:
        model_path (str, optional): Ruta al modelo entrenado.
    """
    # Cargar el modelo entrenado
    model = STFTClassifier(n_classes=2)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # Crear instancia de Plotter con n_bands=129
    labels = ['Seno', 'Coseno']
    plotter = Plotter(n_bands=129, n_classes=2, msd_labels=labels)

    try:
        while True:
            # Selección aleatoria de la clase
            label = random.randint(0, 1)
            func = ['sine', 'cosine'][label]

            # Parámetros aleatorios
            freq = random.uniform(1, 50)  # Frecuencia entre 1 y 50 Hz
            phase = random.uniform(0, 2 * np.pi)  # Fase entre 0 y 2π

            # Generación de la señal
            signal = generate_signal(func, freq, phase)

            # Cálculo de STFT
            stft = compute_stft(signal).unsqueeze(0).unsqueeze(0)  # [1, 1, freq_bins, time_frames]
            stft = stft.to(device)

            # Clasificación
            with torch.no_grad():
                output = model(stft)
                probabilities = F.softmax(output, dim=1).cpu().numpy()[0]

            # Preparar datos para la gráfica
            spec_col = stft.cpu().numpy().squeeze(0).squeeze(0)  # [freq_bins=129, time_frames]
            act_col = probabilities.reshape(-1, 1)  # [n_classes=2, 1]

            # Asegurarse de que spec_col tiene la dimensión correcta (n_bands, win_size)
            # Si spec_col tiene más columnas que win_size, tomar las últimas win_size columnas
            win_size = plotter.win_size
            if spec_col.shape[1] > win_size:
                spec_col = spec_col[:, -win_size:]
            elif spec_col.shape[1] < win_size:
                # Si hay menos columnas, rellenar con ceros a la izquierda
                padding = win_size - spec_col.shape[1]
                spec_col = np.pad(spec_col, ((0,0),(padding,0)), mode='constant')

            # Actualizar la señal en tiempo
            # Para la gráfica de la señal, tomaremos una ventana de la señal generada
            # Ajustamos la longitud para que coincida con plotter.signal_length
            if len(signal) > plotter.signal_length:
                signal_plot = signal[-plotter.signal_length:]
            else:
                padding = plotter.signal_length - len(signal)
                signal_plot = np.pad(signal, (padding, 0), 'constant')

            # Actualizar la gráfica
            plotter.update(signal_plot, spec_col, act_col)

            # Pausa para simular tiempo real (ajusta según sea necesario)
            time.sleep(0.5)

    except KeyboardInterrupt:
        print("Finalizando la visualización en tiempo real.")

# ---------------------------- MAIN ----------------------------

if __name__ == "__main__":
    # Verificar si el modelo ya está entrenado
    modelo_guardado = "stft_classifier.pth"
    if not os.path.exists(modelo_guardado):
        print("Entrenando el modelo...")
        train_model()
    else:
        print("Modelo ya entrenado. Iniciando la visualización en tiempo real.")

    # Iniciar la visualización en tiempo real
    real_time_plotting(model_path=modelo_guardado)
























import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import torch
import torchaudio
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import random
import time
import os
%matplotlib qt

# Configuración de Matplotlib para usar una ventana externa (Qt)
# Si estás ejecutando esto en un script de Python estándar, puedes usar 'plt.ion()' y 'plt.show()'
# En entornos como Jupyter, podrías necesitar cambiar el backend
# %matplotlib qt  # Comenta esta línea si no estás usando Jupyter

# ---------------------------- CLASE PLOTTER ----------------------------

class Plotter():
    def __init__(self, fs=8000, win_size=96, n_wins=10, n_bands=129, n_classes=2, msd_labels=None, FIG_SIZE=(12, 8), blit=True):
        """
        Inicializa la clase Plotter con tres subgráficas: Señal en Tiempo, Espectrograma y Activaciones de Clase.

        Args:
            fs (int): Frecuencia de muestreo en Hz.
            win_size (int): Tamaño de la ventana para la actualización del espectrograma.
            n_wins (int): Número de ventanas para mostrar en el espectrograma y activaciones.
            n_bands (int): Número de bandas de frecuencia en el espectrograma.
            n_classes (int): Número de clases para las activaciones.
            msd_labels (list, optional): Etiquetas de las clases.
            FIG_SIZE (tuple, optional): Tamaño de la figura.
            blit (bool, optional): Si se usa blitting para actualizaciones más eficientes.
        """
        # Inicializar parámetros
        self.blit = blit
        self.win_size = win_size
        self.n_wins = n_wins
        self.n_bands = n_bands
        self.n_classes = n_classes
        self.msd_labels = msd_labels
        self.fs = fs  # Frecuencia de muestreo

        # Inicializar datos para las gráficas
        # Señal en Tiempo
        self.signal_length = 1024  # Longitud de la señal a mostrar
        self.signal = np.zeros(self.signal_length)
        self.time = np.linspace(0, self.signal_length / self.fs, self.signal_length)  # Eje X en segundos

        # Espectrograma
        self.spec = np.zeros((n_bands, win_size * n_wins))

        # Activaciones de Clase
        self.act = np.zeros((n_classes, n_wins))

        # Configurar figuras
        self.fig, (self.ax_signal, self.ax_spec, self.ax_act) = plt.subplots(3, 1, figsize=FIG_SIZE)

        # Señal en Tiempo
        self.line_signal, = self.ax_signal.plot(self.time, self.signal, color='blue')
        self.ax_signal.set_title("Señal en Tiempo")
        self.ax_signal.set_xlabel("Tiempo (s)")
        self.ax_signal.set_ylabel("Amplitud")
        self.ax_signal.set_xlim(0, self.signal_length / self.fs)
        self.ax_signal.set_ylim(-1.5, 1.5)

        # Crear el cuadro (rectangle) para la señal
        self.rect = patches.Rectangle((0, -1.5), self.signal_length / self.fs, 3.0, linewidth=2, edgecolor='green', facecolor='none', alpha=0.7)
        self.ax_signal.add_patch(self.rect)

        # Espectrograma
        self.img_spec = self.ax_spec.imshow(self.spec, vmin=0, vmax=1, interpolation="None", cmap="jet", aspect='auto')
        self.ax_spec.set_title("Espectrograma")
        self.ax_spec.invert_yaxis()

        # Activaciones de Clase
        self.img_act = self.ax_act.imshow(self.act, vmin=0, vmax=1, interpolation="none", aspect='auto')
        self.ax_act.set_title("Activaciones de Clase")

        if msd_labels is not None:
            self.ax_act.set_yticks(np.linspace(0, len(msd_labels), len(msd_labels), endpoint=False))
            self.ax_act.set_yticklabels(msd_labels)
            self.ax_act.set_ylim(-0.5, len(msd_labels)-0.5)

        self.fig.tight_layout()
        self.fig.canvas.draw()

        if self.blit:
            # Cachear el fondo de las gráficas
            self.axbackground_signal = self.fig.canvas.copy_from_bbox(self.ax_signal.bbox)
            self.axbackground_spec = self.fig.canvas.copy_from_bbox(self.ax_spec.bbox)
            self.axbackground_act = self.fig.canvas.copy_from_bbox(self.ax_act.bbox)

        plt.ion()  # Modo interactivo
        plt.show()

    def update(self, new_signal, new_spec_col, new_act_col, label):
        """
        Actualiza las gráficas con nuevos datos y dibuja un cuadro en la señal en tiempo.

        Args:
            new_signal (np.ndarray): Nueva señal en tiempo para actualizar.
            new_spec_col (np.ndarray): Nueva columna de espectrograma.
            new_act_col (np.ndarray): Nuevas activaciones de clase.
            label (int): Etiqueta de clasificación (0 para 'seno', 1 para 'coseno').
        """
        # Actualizar la señal en tiempo
        self.signal = np.delete(self.signal, [k for k in range(len(new_signal))], axis=0)
        self.signal = np.concatenate((self.signal, new_signal), axis=0)
        self.line_signal.set_ydata(self.signal)

        # Actualizar los datos del espectrograma
        self.spec = np.delete(self.spec, [k for k in range(self.win_size)], axis=1)
        self.spec = np.concatenate((self.spec, new_spec_col), axis=1)
        self.img_spec.set_data(self.spec)
        self.img_spec.autoscale()

        # Actualizar las activaciones de clase
        self.act = np.delete(self.act, 0, axis=1)
        self.act = np.concatenate((self.act, new_act_col), axis=1)
        self.img_act.set_data(self.act)
        self.img_act.autoscale()

        # Calcular los límites del cuadro
        start_time = 0  # Inicio en 0 segundos
        end_time = self.signal_length / self.fs  # Fin en segundos
        min_amp = self.signal.min()
        max_amp = self.signal.max()

        # Actualizar las coordenadas y propiedades del cuadro
        self.rect.set_xy((start_time, min_amp))
        self.rect.set_width(end_time - start_time)
        self.rect.set_height(max_amp - min_amp)

        # Cambiar el color del cuadro según la clasificación
        if label == 0:
            # Seno - azul
            self.rect.set_edgecolor('blue')
        elif label == 1:
            # Coseno - rojo
            self.rect.set_edgecolor('red')
        else:
            # Otro - negro
            self.rect.set_edgecolor('black')

        if self.blit:
            # Restaurar el fondo de las gráficas
            self.fig.canvas.restore_region(self.axbackground_signal)
            self.fig.canvas.restore_region(self.axbackground_spec)
            self.fig.canvas.restore_region(self.axbackground_act)

            # Redibujar los artistas
            self.ax_signal.draw_artist(self.line_signal)
            self.ax_signal.draw_artist(self.rect)  # Dibujar el cuadro
            self.ax_spec.draw_artist(self.img_spec)
            self.ax_act.draw_artist(self.img_act)

            # Actualizar las regiones
            self.fig.canvas.blit(self.ax_signal.bbox)
            self.fig.canvas.blit(self.ax_spec.bbox)
            self.fig.canvas.blit(self.ax_act.bbox)
        else:
            self.fig.canvas.draw()

        self.fig.canvas.flush_events()

# ---------------------------- GENERACIÓN DE SEÑALES ----------------------------

# Parámetros de la señal
fs = 8000  # Frecuencia de muestreo en Hz
duration = 1.0  # Duración en segundos
t = np.linspace(0, duration, int(fs * duration), endpoint=False)

def generate_signal(func, freq=5, phase=0):
    """
    Genera una señal basada en la función especificada.

    Args:
        func (str): 'sine' o 'cosine'.
        freq (float): Frecuencia de la señal en Hz.
        phase (float): Fase de la señal en radianes.

    Returns:
        np.ndarray: Señal generada.
    """
    global t  # Usar la variable global 't'

    if func == 'sine':
        return np.sin(2 * np.pi * freq * t + phase)
    elif func == 'cosine':
        return np.tan(2 * np.pi * freq * t + phase)  # Usar coseno en lugar de tangente
    else:
        raise ValueError("Función desconocida. Usa 'sine' o 'cosine'.")

# ---------------------------- CÁLCULO DE STFT ----------------------------

# Parámetros de STFT
n_fft = 256
hop_length = 128
window = torch.hamming_window(n_fft)

def compute_stft(signal):
    """
    Calcula la STFT de una señal.

    Args:
        signal (np.ndarray): Señal de entrada.

    Returns:
        torch.Tensor: Magnitud de la STFT.
    """
    signal_tensor = torch.tensor(signal, dtype=torch.float32)
    stft = torch.stft(signal_tensor, n_fft=n_fft, hop_length=hop_length, window=window, return_complex=True)
    magnitude = torch.abs(stft)
    # Normalización
    magnitude = magnitude / (magnitude.max() + 1e-8)  # Añadir epsilon para evitar división por cero
    return magnitude

# ---------------------------- DATASET Y DATA LOADER ----------------------------

class TrigDataset(Dataset):
    def __init__(self, num_samples=1000, transform=None):
        """
        Inicializa el dataset.

        Args:
            num_samples (int): Número total de muestras.
            transform (callable, optional): Transformación a aplicar.
        """
        self.num_samples = num_samples
        self.transform = transform
        self.classes = ['sine', 'cosine']  # Dos clases

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # Selección aleatoria de la clase
        label = random.randint(0, 1)
        func = self.classes[label]

        # Parámetros aleatorios
        freq = random.uniform(1, 50)  # Frecuencia entre 1 y 50 Hz
        phase = random.uniform(0, 2 * np.pi)  # Fase entre 0 y 2π

        # Generación de la señal
        signal = generate_signal(func, freq, phase)

        # Cálculo de STFT
        stft = compute_stft(signal)

        # Opcional: aplicar transformaciones adicionales
        if self.transform:
            stft = self.transform(stft)

        # Añadir un canal adicional para compatibilidad con CNN
        stft = stft.unsqueeze(0)  # [1, freq_bins, time_frames]

        return stft, label

# ---------------------------- MODELO DE CLASIFICACIÓN ----------------------------

class STFTClassifier(nn.Module):
    def __init__(self, n_classes=2):
        super(STFTClassifier, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # [batch, 1, freq_bins, time_frames]
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # [batch, 16, freq_bins/2, time_frames/2]

        # Calculamos el tamaño después de las capas convolucionales y de pooling
        # Para n_fft=256, freq_bins=129
        # Después de la primera pooling: 129 / 2 = 64 (MaxPool2d truncará a 64)
        # Después de la segunda pooling: 64 / 2 = 32
        # Suponiendo time_frames=62 después de STFT
        # Después de pooling: 62 / 2 = 31, luego 31 / 2 = 15 (truncado)
        # Así que la salida de conv2 es [batch, 32, 32, 15]

        self.fc1 = nn.Linear(32 * 32 * 15, 128)  # Ajusta según las dimensiones reales
        self.fc2 = nn.Linear(128, n_classes)  # 2 clases: sine, cosine

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # [batch, 16, 64, 31]
        x = self.pool(F.relu(self.conv2(x)))  # [batch, 32, 32, 15]
        x = x.view(x.size(0), -1)  # Aplanar
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ---------------------------- ENTRENAMIENTO DEL MODELO ----------------------------

def train_model():
    """
    Entrena el modelo STFTClassifier con el dataset TrigDataset.
    """
    # Crear datasets de entrenamiento y prueba
    train_dataset = TrigDataset(num_samples=3000)
    test_dataset = TrigDataset(num_samples=600)

    # Crear DataLoaders
    batch_size = 16
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Instanciar el modelo, la función de pérdida y el optimizador
    model = STFTClassifier(n_classes=2)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Entrenamiento
    num_epochs = 10
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(num_epochs):
        running_loss = 0.0
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zerar gradientes
            optimizer.zero_grad()

            # Forward
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_dataset)

        # Evaluación en el conjunto de prueba
        model.eval()
        correct = 0
        total = 0
        confusion_matrix = np.zeros((2, 2), dtype=int)

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                # Construcción de la matriz de confusión
                for t_label, p_label in zip(labels.view(-1), predicted.view(-1)):
                    confusion_matrix[t_label.long(), p_label.long()] += 1

        accuracy = correct / total * 100
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Test Accuracy: {accuracy:.2f}%")

    # Evaluación final
    model.eval()
    correct = 0
    total = 0
    confusion_matrix = np.zeros((2, 2), dtype=int)

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # Construcción de la matriz de confusión
            for t_label, p_label in zip(labels.view(-1), predicted.view(-1)):
                confusion_matrix[t_label.long(), p_label.long()] += 1

    accuracy = correct / total * 100
    print(f"Precisión en el conjunto de prueba: {accuracy:.2f}%")
    print("Matriz de Confusión:")
    print(confusion_matrix)

    # Guardar el modelo entrenado
    torch.save(model.state_dict(), "stft_classifier.pth")
    print("Modelo guardado como 'stft_classifier.pth'.")

# ---------------------------- VISUALIZACIÓN EN TIEMPO REAL ----------------------------

def real_time_plotting(model_path="stft_classifier.pth"):
    """
    Inicia la visualización en tiempo real de la señal, el espectrograma y las activaciones de clase.

    Args:
        model_path (str, optional): Ruta al modelo entrenado.
    """
    # Cargar el modelo entrenado
    model = STFTClassifier(n_classes=2)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # Crear instancia de Plotter con n_bands=129 y frecuencia de muestreo fs=8000
    labels = ['Seno', 'Coseno']
    plotter = Plotter(fs=8000, n_bands=129, n_classes=2, msd_labels=labels)

    try:
        while True:
            # Selección aleatoria de la clase
            label = random.randint(0, 1)
            func = ['sine', 'cosine'][label]

            # Parámetros aleatorios
            freq = random.uniform(1, 50)  # Frecuencia entre 1 y 50 Hz
            phase = random.uniform(0, 2 * np.pi)  # Fase entre 0 y 2π

            # Generación de la señal
            signal = generate_signal(func, freq, phase)

            # Cálculo de STFT
            stft = compute_stft(signal).unsqueeze(0).unsqueeze(0)  # [1, 1, freq_bins, time_frames]
            stft = stft.to(device)

            # Clasificación
            with torch.no_grad():
                output = model(stft)
                probabilities = F.softmax(output, dim=1).cpu().numpy()[0]
                predicted_label = np.argmax(probabilities)

            # Preparar datos para la gráfica
            spec_col = stft.cpu().numpy().squeeze(0).squeeze(0)  # [freq_bins=129, time_frames]
            act_col = probabilities.reshape(-1, 1)  # [n_classes=2, 1]

            # Asegurarse de que spec_col tiene la dimensión correcta (n_bands, win_size)
            # Si spec_col tiene más columnas que win_size, tomar las últimas win_size columnas
            win_size = plotter.win_size
            if spec_col.shape[1] > win_size:
                spec_col = spec_col[:, -win_size:]
            elif spec_col.shape[1] < win_size:
                # Si hay menos columnas, rellenar con ceros a la izquierda
                padding = win_size - spec_col.shape[1]
                spec_col = np.pad(spec_col, ((0,0),(padding,0)), mode='constant')

            # Actualizar la señal en tiempo
            # Para la gráfica de la señal, tomaremos una ventana de la señal generada
            # Ajustamos la longitud para que coincida con plotter.signal_length
            if len(signal) > plotter.signal_length:
                signal_plot = signal[-plotter.signal_length:]
            else:
                padding = plotter.signal_length - len(signal)
                signal_plot = np.pad(signal, (padding, 0), 'constant')

            # Actualizar la gráfica pasando la etiqueta de clasificación
            plotter.update(signal_plot, spec_col, act_col, predicted_label)

            # Pausa para simular tiempo real (ajusta según sea necesario)
            time.sleep(0.5)

    except KeyboardInterrupt:
        print("Finalizando la visualización en tiempo real.")

# ---------------------------- MAIN ----------------------------

if __name__ == "__main__":
    # Verificar si el modelo ya está entrenado
    modelo_guardado = "stft_classifier.pth"
    if not os.path.exists(modelo_guardado):
        print("Entrenando el modelo...")
        train_model()
    else:
        print("Modelo ya entrenado. Iniciando la visualización en tiempo real.")

    # Iniciar la visualización en tiempo real
    real_time_plotting(model_path=modelo_guardado)




